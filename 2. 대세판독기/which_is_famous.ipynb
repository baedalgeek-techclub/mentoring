{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 크롤러 튜토리얼\n",
    "\n",
    "이거 하나로 나도 크롤링 전문가!\n",
    "\n",
    "Copyright 2020. `Ho Kim`. All rights reversed, For education only."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## POST 신호 보내보기\n",
    "\n",
    "HTTP 에서 웹 페이지에 접근하는 방법이 여러가지가 있습니다.\n",
    "* GET\n",
    "* POST\n",
    "* ...\n",
    "\n",
    "그중, 가장 자주 쓰이는 친구들은 GET과 POST의 2가지입니다.\n",
    "\n",
    "GET은 웹 링크(URL)에 변수들을 실어나를 수 있습니다. 길이 제한이 있고, 비밀번호 같은건 보안에 취약해 전송할 수 없습니다.\n",
    "\n",
    "POST는 웹 패킷에 변수들을 실어나를 수 있습니다. 암호화를 할 수 있어 GET보다 안전합니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 라이브러리가 Jupyter Notebook에 그림을 그릴 수 있도록 합니다.\n",
    "%matplotlib inline\n",
    "\n",
    "# --------------------------------------\n",
    "#  아래 라이브러리는 수동으로 설치해야 합니다.\n",
    "# --------------------------------------\n",
    "\n",
    "from google_images_download import google_images_download as gid  # 이미지 크롤링 라이브러리\n",
    "from PIL import Image  # 이미지 라이브러리\n",
    "\n",
    "# 웹 크롤러 라이브러리 로드하기\n",
    "import requests  # cURL 라이브러리\n",
    "\n",
    "# 데이터과학 라이브러리 로드하기\n",
    "import pandas as pd  # 데이터 가공 라이브러리\n",
    "import matplotlib.pyplot as plt  # 시각화 라이브러리\n",
    "import xlrd as _  # 엑셀 파일 파싱 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET 보내기\n",
    "url = 'https://datalab.naver.com/keyword/trendSearch.naver'\n",
    "\n",
    "r = requests.get(url)\n",
    "r.text.split('<title>')[1].split('</title>')[0]"
   ]
  },
  {
   "source": [
    "## 헤더 보안이 적용된 웹 페이지 뚫기\n",
    "\n",
    "정상적인 인터넷 브라우저로 위의 사이트를 들어가면 분명히 결과가 잘 나옵니다.\n",
    "차이가 무엇일까?\n",
    "\n",
    "인터넷 브라우저가 웹 사이트를 요구할 땐, `User-Agent`라는 특수한 헤더를 포함시킵니다.\n",
    "이 헤더에는 인터넷 브라우저, OS, 웹 엔진에 대한 정보가 들어있습니다.\n",
    "\n",
    "그렇다면, 이 헤더 정보를 같이 보낸다면 정보가 잘 나올 겁니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET 보내기\n",
    "url = 'https://datalab.naver.com/keyword/trendSearch.naver'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'}\n",
    "\n",
    "r = requests.get(url, headers=headers)\n",
    "r.text.split('<title>')[1].split('</title>')[0]"
   ]
  },
  {
   "source": [
    "## Naver 공략하기\n",
    "\n",
    "이전에 우리가 공략해야 할 URL `https://datalab.naver.com/qcHash.naver`를 얻었습니다.\n",
    "\n",
    "그리고, 이 사이트가 POST를 사용한다는 것을 알고 있습니다.\n",
    "\n",
    "이제, 이 사이트를 공략해야 할 시간입니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://datalab.naver.com/qcHash.naver'\n",
    "\n",
    "r = requests.post(\n",
    "    url,\n",
    "    headers={\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36',\n",
    "        # 어느 사이트에서 이 경로를 요청하는가?\n",
    "        'referer': r'https://datalab.naver.com/keyword/trendSearch.naver',\n",
    "    },\n",
    "    params={\n",
    "        'queryGroups': '트와이스__SZLIG__트와이스__OUML__블랙핑크__SZLIG__블랙핑크',\n",
    "        'startDate': 20191007,\n",
    "        'endDate': 20201007,\n",
    "        'timeUnit': 'date',\n",
    "        'gender': '',\n",
    "        'age': '',\n",
    "        'device': '',\n",
    "    },\n",
    ")\n",
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashKey 가져오기\n",
    "hash_key = r.json()['hashKey']\n",
    "hash_key"
   ]
  },
  {
   "source": [
    "## 결과 파일 다운로드하기\n",
    "\n",
    "이전에 결과 파일을 다운로드하는 URL도 구했습니다.\n",
    "\n",
    "이제, 이 URL에 접속해서 결과 엑셀 파일을 다운로드할 시간입니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://datalab.naver.com/qcExcel.naver'\n",
    "\n",
    "# 결과 파일 다운로드하기\n",
    "r = requests.get(\n",
    "    url,\n",
    "    headers={\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36',\n",
    "    },\n",
    "    params={\n",
    "        'hashKey': hash_key,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 엑셀 파일 파싱하기\n",
    "df = pd.read_excel(r.content)\n",
    "df"
   ]
  },
  {
   "source": [
    "## 데이터 가공하기\n",
    "\n",
    "와! 트와이스 vs 블랙핑크 트렌드 데이터를 가져왔습니다.\n",
    "\n",
    "그런데, 뭔가 이상합니다.\n",
    "데이터에 필요없는 행이 앞에 6개나 있습니다.\n",
    "\n",
    "이 필요없는 데이터 행을 제거하는 방법이 있습니다.\n",
    "바로, 특정 행부터 데이터가 있다고 파싱 함수에 알려주는 겁니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀 파일 파싱하기\n",
    "df = pd.read_excel(r.content, header=6)\n",
    "df"
   ]
  },
  {
   "source": [
    "성공입니다.\n",
    "그런데 날짜가 중복되는 것이 조금 거슬립니다.\n",
    "\n",
    "중복되는 날짜를 제거하는 방법이 있습니다.\n",
    "파이썬의 `del` 함수를 써서 아래처럼 필요없는 열을 제거할 수도 있습니다.\n",
    "\n",
    "```python\n",
    "del df['날짜.1']\n",
    "```\n",
    "\n",
    "그리고, `drop` 함수를 사용해서 아래처럼 여러 열을 제거할 수 있습니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복되는 열 제거하기\n",
    "df = df.drop(df.columns[2::2], 1)\n",
    "df"
   ]
  },
  {
   "source": [
    "## API 만들기\n",
    "\n",
    "짜잔! 이제 모든 구현이 끝났습니다.\n",
    "이제 이 기능을 쉽게 사용할 수 있는 API 함수를 만들 시간입니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API로 만들기\n",
    "def get_trend(*, query, start_date, end_date, gender='', age='', device=''):\n",
    "    url = 'https://datalab.naver.com/qcHash.naver'\n",
    "\n",
    "    # hashKey 요청하기\n",
    "    query = '__OUML__'.join('__SZLIG__'.join([k, k] + v) for k, v in query.items())\n",
    "    r = requests.post(\n",
    "        url,\n",
    "        headers={\n",
    "            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36',\n",
    "            # 어느 사이트에서 이 경로를 요청하는가?\n",
    "            'referer': r'https://datalab.naver.com/keyword/trendSearch.naver',\n",
    "        },\n",
    "        params={\n",
    "            'queryGroups': query,\n",
    "            'startDate': start_date,\n",
    "            'endDate': end_date,\n",
    "            'timeUnit': 'date',\n",
    "            'gender': gender,\n",
    "            'age': age,\n",
    "            'device': device,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # hashKey 가져오기\n",
    "    hash_key = r.json()['hashKey']\n",
    "\n",
    "    url = 'https://datalab.naver.com/qcExcel.naver'\n",
    "\n",
    "    # 결과 파일 다운로드하기\n",
    "    r = requests.get(\n",
    "        url,\n",
    "        headers={\n",
    "            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36',\n",
    "        },\n",
    "        params={\n",
    "            'hashKey': hash_key,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # 엑셀 파일 파싱하기\n",
    "    df = pd.read_excel(r.content, header=6, )\n",
    "\n",
    "    # 데이터 가공하기\n",
    "    df = df.drop(df.columns[2::2], 1)  # 날짜 열이 중복되니 없앱니다.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 호출하기\n",
    "get_trend(\n",
    "    query={\n",
    "        # \"주제어\": [\"검색어\", ...],\n",
    "        '트와이스': [],\n",
    "        '블랙핑크': [],\n",
    "    },\n",
    "    start_date=20191007,\n",
    "    end_date=20201007,\n",
    ")"
   ]
  },
  {
   "source": [
    "## 시각화\n",
    "\n",
    "데이터가 화면에 좌르륵 보이는 게 참 좋긴 한데,\n",
    "역시 데이터는 차트로 봐야 더 멋있는 법입니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트 설정\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "\n",
    "# 시각화하기\n",
    "df.plot(x='날짜', xlabel='', ylabel='검색량', rot=90);"
   ]
  },
  {
   "source": [
    "## 대세 분석하기\n",
    "\n",
    "트와이스 vs 블랙핑크 싸움 실화냐? 가슴이 웅장해진다..\n",
    "\n",
    "이제 마지막 단계, 어느 쪽이 대세인지 판단할 차롑니다.\n",
    "\n",
    "사실 이것만 가지고는 어디가 대세인지 단정지을 수가 없습니다.\n",
    "그래서 그냥, 검색량이 더 많은 날을 세서, 더 많은 쪽이 대세라고 하겠습니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대세 판독하기\n",
    "keyword_1 = df[df.columns[1]]\n",
    "keyword_2 = df[df.columns[2]]\n",
    "is_keyword_1_more_famous = (keyword_1 > keyword_2).mean() >= 0.5\n",
    "is_keyword_1_more_famous  # True면, keyword_1 이 더 인기가 많은 것이다."
   ]
  },
  {
   "source": [
    "## API 만들기 2\n",
    "\n",
    "이제 마지막으로, 키워드만 넣으면 어느 쪽이 대세인지 판단하는 함수를 만듭시다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_is_famous(*names, start_date=20191007, end_date=20201007):\n",
    "    # 트렌드 정보 불러오기\n",
    "    df = get_trend(\n",
    "        query={n: [] for n in names},\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "    )\n",
    "\n",
    "    # 대세 분석하기\n",
    "    keyword_1 = df[df.columns[1]]\n",
    "    keyword_2 = df[df.columns[2]]\n",
    "    is_keyword_1_more_famous = (keyword_1 > keyword_2).mean() >= 0.5\n",
    "\n",
    "    name = names[0] if is_keyword_1_more_famous else names[1]\n",
    "\n",
    "    # 대세 이미지 불러오기\n",
    "    response = gid.googleimagesdownload()\n",
    "    paths = response.download({\n",
    "        'keywords': name,\n",
    "        'limit': 2,\n",
    "        'no_download': True,\n",
    "        'silent_mode': True,\n",
    "    })\n",
    "    url = paths[0][name][1]\n",
    "\n",
    "    r = requests.get(url, stream=True)\n",
    "    im = Image.open(r.raw)\n",
    "\n",
    "    # 대세 발표하기\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트와이스 vs 블랙핑크, 그 승자는?\n",
    "which_is_famous('트와이스', '블랙핑크')"
   ]
  },
  {
   "source": [
    "ㄹㅇㅋㅋ"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}